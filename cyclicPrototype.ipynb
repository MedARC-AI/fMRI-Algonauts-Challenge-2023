{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Do WANDB\n",
    "1. Use full COCO webdaset in \"/fsx/proj-medarc/fmri/coco/unlabeled2017\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get custom models and functions\n",
    "import sys\n",
    "# sys.path.append('../fMRI-reconstruction-NSD/src')\n",
    "sys.path.append('/fsx/proj-medarc/fmri/fMRI-reconstruction-NSD/src/')\n",
    "from models import Clipper, BrainNetwork\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm # for jupyter notebook\n",
    "from accelerate import Accelerator\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "Mixed precision type: no\n",
      "\n",
      "distributed = False num_devices = 1 local rank = 0 world size = 1\n"
     ]
    }
   ],
   "source": [
    "# uses tf32 data type which is faster than standard float32\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# Multi-GPU config #\n",
    "accelerator = Accelerator()\n",
    "print = accelerator.print # only print if local_rank=0\n",
    "\n",
    "device = accelerator.device\n",
    "print(\"device:\",device)\n",
    "\n",
    "num_devices = torch.cuda.device_count()\n",
    "if num_devices==0: num_devices = 1\n",
    "num_workers = num_devices\n",
    "\n",
    "print(accelerator.state)\n",
    "local_rank = accelerator.state.local_process_index\n",
    "world_size = accelerator.state.num_processes\n",
    "if num_devices<=1 and world_size<=1:\n",
    "    distributed=False\n",
    "else:\n",
    "    distributed=True\n",
    "print(\"distributed =\",distributed,\"num_devices =\", num_devices, \"local rank =\", local_rank, \"world size =\", world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = '../algonauts_2023_challenge_data'\n",
    "data_dir = \"/fsx/proj-medarc/fmri/natural-scenes-dataset/algonauts_data/dataset\"\n",
    "# parent_submission_dir = 'algonauts_2023_challenge_submission'\n",
    "parent_submission_dir = \"/fsx/proj-medarc/fmri/dweisberg/fMRI-Algonauts-Challenge-2023/algonauts_2023_challenge_submission\"\n",
    "\n",
    "subj = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--model_name=testing', '--clip_variant=ViT-L/14', '--batch_size=32']\n"
     ]
    }
   ],
   "source": [
    "# can specify jupyter_args here for argparser to use if running this code interactively\n",
    "if utils.is_interactive():\n",
    "    jupyter_args=[]\n",
    "    jupyter_args.append(\"--model_name=testing\")\n",
    "    jupyter_args.append(\"--clip_variant=ViT-L/14\")\n",
    "    jupyter_args.append(\"--batch_size=32\") # smaller to account for more loaded models.\n",
    "#     jupyter_args.append(\"--resume_from_ckpt\")\n",
    "    print(jupyter_args)\n",
    "    \n",
    "    %load_ext autoreload\n",
    "    %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Model Training Configuration\")\n",
    "parser.add_argument(\n",
    "    \"--model_name\", type=str, default=\"testing\",\n",
    "    help=\"name of model, used for ckpt saving and wandb logging\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--batch_size\", type=int, default=300,\n",
    "    help=\"Our maximum for A100 was 300 for 1dim voxels and 128 for 3dim voxels\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--clip_variant\",type=str,default=\"ViT-L/14\",choices=[\"RN50\", \"ViT-L/14\", \"ViT-B/32\", \"ViT-H-14\", \"RN50x64\"],\n",
    "    help='clip / openclip variant',\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--outdir\",type=str,default=None,\n",
    "    help=\"output directory for logs and checkpoints\",\n",
    ")\n",
    "# doesn't work in python 3.8\n",
    "# parser.add_argument(\n",
    "#     \"--resume_from_ckpt\",action=argparse.BooleanOptionalAction,default=False,\n",
    "#     help=\"if not using wandb and want to resume from a ckpt\",\n",
    "# )\n",
    "parser.add_argument(\n",
    "    '--resume_from_ckpt',\n",
    "    action='store_true',\n",
    "    default=False,\n",
    "    help='if not using wandb and want to resume from a ckpt.',\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_steps\",type=int,default=90000,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--lr_scheduler\",type=str,default='cycle',choices=['cycle','fixed'],\n",
    ")\n",
    "# doesn't work in python 3.8\n",
    "# parser.add_argument(\n",
    "#     \"--ckpt_saving\",action=argparse.BooleanOptionalAction,default=True,\n",
    "# )\n",
    "parser.add_argument(\n",
    "    '--no_ckpt_saving',\n",
    "    action='store_false',\n",
    "    default=True,\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--ckpt_interval\",type=int,default=50,\n",
    "    help=\"save ckpt every x steps\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--val_interval\",type=int,default=50,\n",
    "    help=\"get validation loss every x steps\",\n",
    ")\n",
    "# parser.add_argument(\n",
    "#     \"--save_at_end\",action=argparse.BooleanOptionalAction,default=False,\n",
    "#     help=\"if False, will save best.ckpt whenever interval shows best validation score\",\n",
    "# )\n",
    "parser.add_argument(\n",
    "    '--save_at_end',\n",
    "    action='store_true',\n",
    "    default=False,\n",
    "    help='if False, will save best.ckpt whenever interval shows best validation score',\n",
    ")\n",
    "# parser.add_argument(\n",
    "#     \"--seed\",type=int,default=42,\n",
    "# )\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--max_lr\",type=float,default=3e-4,\n",
    ")\n",
    "\n",
    "if utils.is_interactive():\n",
    "    args = parser.parse_args(jupyter_args)\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "# create global variables without the args prefix\n",
    "for attribute_name in vars(args).keys():\n",
    "    globals()[attribute_name] = getattr(args, attribute_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if outdir is None:\n",
    "    outdir = os.path.abspath(f'train_logs/{model_name}')\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Models and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for dataloaders\n",
    "\n",
    "def _transforms(n_px=256, reshape=False):\n",
    "    if reshape:\n",
    "        transform = transforms.Compose([\n",
    "        transforms.CenterCrop(n_px),\n",
    "        transforms.Resize(256),\n",
    "        transforms.ToTensor(), # convert the images to a PyTorch tensor\n",
    "            ])\n",
    "    else:\n",
    "        transform = transforms.Compose([\n",
    "        transforms.ToTensor(), # convert the images to a PyTorch tensor\n",
    "            ])\n",
    "    return transform\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, imgs_paths, idxs, transform=None):\n",
    "        self.imgs_paths = np.array(imgs_paths)[idxs]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the image\n",
    "        img_path = self.imgs_paths[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        # Preprocess the image and send it to the chosen device ('cpu' or 'cuda')\n",
    "        if self.transform:\n",
    "            n_px = min(img.size)\n",
    "            img = self.transform(n_px, reshape=True)(img).to(device)\n",
    "        else:\n",
    "            img = _transforms()(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training COCO images: 111063\n",
      "\n",
      "Validation COCO images: 12340\n"
     ]
    }
   ],
   "source": [
    "# coco_dir = \"/scratch/gpfs/KNORMAN/COCO/unlabeled2017_all\"\n",
    "coco_dir = \"/fsx/proj-medarc/fmri/coco/unlabeled2017\"\n",
    "\n",
    "# Create list with all file names, sorted\n",
    "coco_list = os.listdir(coco_dir)\n",
    "coco_list.sort()\n",
    "\n",
    "rand_seed = 5 \n",
    "np.random.seed(rand_seed)\n",
    "\n",
    "# Calculate how many COCO images correspond to 90% for training\n",
    "num_train_coco = int(np.round(len(coco_list) / 100 * 90))\n",
    "# Shuffle all training stimulus images\n",
    "idxs_coco = np.arange(len(coco_list))\n",
    "# np.random.shuffle(idxs)\n",
    "# Assign 90% of the shuffled images to the training partition,\n",
    "# and 10% to the test partition\n",
    "idxs_train_coco, idxs_val_coco = idxs_coco[:num_train_coco], idxs_coco[num_train_coco:]\n",
    "\n",
    "print('Training COCO images: ' + format(len(idxs_train_coco)))\n",
    "print('\\nValidation COCO images: ' + format(len(idxs_val_coco)))\n",
    "\n",
    "# Get the paths of all image files\n",
    "coco_paths = sorted(list(Path(coco_dir).iterdir()))\n",
    "# The DataLoaders contain the ImageDataset class\n",
    "train_coco_dl = DataLoader(\n",
    "    ImageDataset(coco_paths, idxs_train_coco, _transforms), \n",
    "    batch_size=batch_size, \n",
    ")\n",
    "val_coco_dl = DataLoader(\n",
    "    ImageDataset(coco_paths, idxs_val_coco, _transforms), \n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Algonauts Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 9841\n",
      "Test images: 159\n",
      "Training stimulus images: 8857\n",
      "\n",
      "Validation stimulus images: 984\n",
      "\n",
      "Test stimulus images: 159\n"
     ]
    }
   ],
   "source": [
    "class argObj:\n",
    "  def __init__(self, data_dir, parent_submission_dir, subj):\n",
    "    \n",
    "    self.subj = format(subj, '02')\n",
    "    self.data_dir = os.path.join(data_dir, 'subj'+self.subj)\n",
    "    self.parent_submission_dir = parent_submission_dir\n",
    "    self.subject_submission_dir = os.path.join(self.parent_submission_dir,\n",
    "        'subj'+self.subj)\n",
    "\n",
    "    # Create the submission directory if not existing\n",
    "    if not os.path.isdir(self.subject_submission_dir):\n",
    "        os.makedirs(self.subject_submission_dir)\n",
    "\n",
    "args = argObj(data_dir, parent_submission_dir, subj)\n",
    "\n",
    "train_img_dir  = os.path.join(args.data_dir, 'training_split', 'training_images')\n",
    "test_img_dir  = os.path.join(args.data_dir, 'test_split', 'test_images')\n",
    "\n",
    "# Create lists will all training and test image file names, sorted\n",
    "train_img_list = os.listdir(train_img_dir)\n",
    "train_img_list.sort()\n",
    "test_img_list = os.listdir(test_img_dir)\n",
    "test_img_list.sort()\n",
    "print('Training images: ' + str(len(train_img_list)))\n",
    "print('Test images: ' + str(len(test_img_list)))\n",
    "\n",
    "# Calculate how many stimulus images correspond to 90% of the training data\n",
    "num_train = int(np.round(len(train_img_list) / 100 * 90))\n",
    "# Shuffle all training stimulus images\n",
    "idxs = np.arange(len(train_img_list))\n",
    "# np.random.shuffle(idxs)\n",
    "# Assign 90% of the shuffled stimulus images to the training partition,\n",
    "# and 10% to the test partition\n",
    "idxs_train, idxs_val = idxs[:num_train], idxs[num_train:]\n",
    "# No need to shuffle or split the test stimulus images\n",
    "idxs_test = np.arange(len(test_img_list))\n",
    "\n",
    "print('Training stimulus images: ' + format(len(idxs_train)))\n",
    "print('\\nValidation stimulus images: ' + format(len(idxs_val)))\n",
    "print('\\nTest stimulus images: ' + format(len(idxs_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Get Algonauts fMRI data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LH training fMRI data shape:\n",
      "(9841, 19004)\n",
      "(Training stimulus images × LH vertices)\n",
      "\n",
      "RH training fMRI data shape:\n",
      "(9841, 20544)\n",
      "(Training stimulus images × RH vertices)\n"
     ]
    }
   ],
   "source": [
    "fmri_dir = os.path.join(args.data_dir, 'training_split', 'training_fmri')\n",
    "lh_fmri = np.load(os.path.join(fmri_dir, 'lh_training_fmri.npy'))\n",
    "rh_fmri = np.load(os.path.join(fmri_dir, 'rh_training_fmri.npy'))\n",
    "\n",
    "print('LH training fMRI data shape:')\n",
    "print(lh_fmri.shape)\n",
    "print('(Training stimulus images × LH vertices)')\n",
    "\n",
    "print('\\nRH training fMRI data shape:')\n",
    "print(rh_fmri.shape)\n",
    "print('(Training stimulus images × RH vertices)')\n",
    "\n",
    "lh_fmri_train = lh_fmri[idxs_train]\n",
    "lh_fmri_val = lh_fmri[idxs_val]\n",
    "rh_fmri_train = rh_fmri[idxs_train]\n",
    "rh_fmri_val = rh_fmri[idxs_val]\n",
    "\n",
    "del lh_fmri, rh_fmri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algonauts Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlgDataset(Dataset):\n",
    "    def __init__(self, imgs_paths, idxs, lh_fmri, rh_fmri, transform=None):\n",
    "        self.imgs_paths = np.array(imgs_paths)[idxs]\n",
    "        self.transform = transform\n",
    "        self.lh_fmri = lh_fmri\n",
    "        self.rh_fmri = rh_fmri\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the image\n",
    "        img_path = self.imgs_paths[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        # Preprocess the image and send it to the chosen device ('cpu' or 'cuda')\n",
    "        if self.transform:\n",
    "            n_px = min(img.size)\n",
    "            img = self.transform(n_px, reshape=True)(img).to(device)\n",
    "        else:\n",
    "            img = _transforms()(img)\n",
    "        return img, torch.from_numpy(self.lh_fmri[idx]), torch.from_numpy(self.rh_fmri[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the paths of all image files\n",
    "train_imgs_paths = sorted(list(Path(train_img_dir).iterdir()))\n",
    "test_imgs_paths = sorted(list(Path(test_img_dir).iterdir()))\n",
    "\n",
    "# Algonauts dataloaders\n",
    "train_alg_dataloader = DataLoader(\n",
    "    AlgDataset(train_imgs_paths, idxs_train, lh_fmri_train, rh_fmri_train), \n",
    "    batch_size=batch_size, \n",
    ")\n",
    "val_alg_dataloader = DataLoader(\n",
    "    AlgDataset(train_imgs_paths, idxs_val, lh_fmri_val, rh_fmri_val), \n",
    "    batch_size=batch_size\n",
    ")\n",
    "# just images\n",
    "test_alg_dataloader = DataLoader(\n",
    "    ImageDataset(test_imgs_paths, idxs_test), \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# training_clip_dir = \"/scratch/gpfs/dw26/algonauts_2023_challenge_data/subj01/training_split/training_clip\"\n",
    "# validation_clip_dir = \"/scratch/gpfs/dw26/algonauts_2023_challenge_data/subj01/training_split/validation_clip\"\n",
    "# test_clip_dir = \"/scratch/gpfs/dw26/algonauts_2023_challenge_data/subj01/test_split/test_clip\"\n",
    "\n",
    "# if not os.path.isdir(training_clip_dir):\n",
    "#     os.makedirs(training_clip_dir)\n",
    "# if not os.path.isdir(validation_clip_dir):\n",
    "#     os.makedirs(validation_clip_dir)\n",
    "# if not os.path.isdir(test_clip_dir):\n",
    "#     os.makedirs(test_clip_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT-L/14 cuda\n"
     ]
    }
   ],
   "source": [
    "# get clipper\n",
    "clip_extractor = Clipper(\"ViT-L/14\", device=torch.device(device)) # run in terminal to download\n",
    "\n",
    "# def img2clipfile(img_paths, dataloader, idxs, clip_dir):\n",
    "#     running_count=0\n",
    "#     for img_batch in tqdm(dataloader):\n",
    "#         clip_batch = clip_extractor.embed_image(img_batch)\n",
    "#         for clip in clip_batch:\n",
    "#             clip = clip.cpu().numpy()\n",
    "#             img_path = img_paths[idxs[running_count]]\n",
    "#             clip_file_name = str(img_path)[-24:-3]+\"npy\"\n",
    "#             np.save(os.path.join(training_clip_dir, clip_file_name), clip)\n",
    "#             running_count+=1\n",
    "        \n",
    "        \n",
    "# img2clipfile(train_imgs_paths, train_imgs_dataloader, idxs_train, training_clip_dir)\n",
    "# img2clipfile(train_imgs_paths, val_imgs_dataloader, idxs_val, validation_clip_dir)\n",
    "# img2clipfile(test_imgs_paths, test_imgs_dataloader, idxs_test, test_clip_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Clip2Vert and Vert2CLip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclePrototype(nn.Module):\n",
    "    def __init__(self, brain_dim, clip_dim, vert2clipPath=None):\n",
    "        super().__init__()\n",
    "        self.brain_dim = dict(out_dim=brain_dim, in_dim=clip_dim)\n",
    "        self.clip_dim = dict(out_dim=clip_dim, in_dim=brain_dim)\n",
    "        self.clip2vert = BrainNetwork(**self.brain_dim)\n",
    "        self.vert2clip = BrainNetwork(**self.clip_dim)\n",
    "        self.vert2clipPath = vert2clipPath\n",
    "\n",
    "        # loading pretrained vert2clip model\n",
    "        if self.vert2clipPath is not None:\n",
    "            checkpoint = torch.load(self.vert2clipPath, map_location=device)\n",
    "            state_dict = checkpoint['model_state_dict']\n",
    "            self.vert2clip.load_state_dict(state_dict)\n",
    "            # freezing the vert2clip model\n",
    "            for param in self.vert2clip.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x, paired=False):\n",
    "        brain = self.clip2vert(x)\n",
    "        x = self.vert2clip(brain)\n",
    "        # whether want both brain activations and predicted clip embedding\n",
    "        if paired:\n",
    "            return brain, x\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained vert2clip model...\n",
      "Brain dimension: 39548\n",
      "CLIP dimension: 768\n",
      "...finished loading pretrained vert2clip model!\n",
      "params of cycle:\n",
      "param counts:\n",
      "464,649,596 total\n",
      "232,344,188 trainable\n",
      "\n",
      "Done with model preparations!\n"
     ]
    }
   ],
   "source": [
    "print(\"Load pretrained vert2clip model...\")\n",
    "brain_dim = lh_fmri_train.shape[1]+rh_fmri_train.shape[1]\n",
    "clip_dim = 768\n",
    "model_path = \"/fsx/proj-medarc/fmri/ckadirt/github/fMRI-reconstruction-NSD/src/test/vert2clip/vert2clip-test_latest.pt\"\n",
    "cycle_kwargs = dict(brain_dim=brain_dim, clip_dim=clip_dim, vert2clipPath=model_path)\n",
    "cycle = CyclePrototype(**cycle_kwargs)\n",
    "print(\"Brain dimension:\", brain_dim)\n",
    "print(\"CLIP dimension:\", clip_dim)\n",
    "print(\"...finished loading pretrained vert2clip model!\")\n",
    "\n",
    "print(\"params of cycle:\")\n",
    "if local_rank==0:\n",
    "    utils.count_params(cycle)\n",
    "    \n",
    "no_decay = ['bias']\n",
    "opt_grouped_parameters = [\n",
    "    {'params': [p for n, p in cycle.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 1e-2},\n",
    "    {'params': [p for n, p in cycle.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = torch.optim.AdamW(opt_grouped_parameters, lr=3e-4) # lr doesnt get used if lr_scheduler='cycle'\n",
    "\n",
    "if lr_scheduler == 'fixed':\n",
    "    lr_scheduler = None\n",
    "elif lr_scheduler == 'cycle':\n",
    "    global_batch_size = batch_size * num_devices\n",
    "    total_steps=num_train_coco//global_batch_size\n",
    "    lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, \n",
    "        max_lr=max_lr,\n",
    "        total_steps=total_steps,\n",
    "        final_div_factor=1000,\n",
    "        last_epoch=-1, pct_start=2/total_steps\n",
    "    )\n",
    "    \n",
    "def save_ckpt(tag):\n",
    "    ckpt_path = outdir+f'/{tag}.pth'\n",
    "    print(f'saving {ckpt_path}',flush=True)\n",
    "    state_dict = cycle.state_dict()\n",
    "    torch.save({\n",
    "        'step': step,\n",
    "        'model_state_dict': cycle.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'lr_scheduler': lr_scheduler.state_dict(),\n",
    "        'train_losses': losses,\n",
    "        'val_losses': val_losses,\n",
    "        'lrs': lrs,\n",
    "        }, ckpt_path)\n",
    "        \n",
    "print(\"\\nDone with model preparations!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Huggingface Accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algonauts images\n",
    "cycle, optimizer, train_alg_dl, val_alg_dl, test_alg_dl, lr_scheduler = accelerator.prepare(\n",
    "    cycle, optimizer, train_alg_dataloader, val_alg_dataloader, test_alg_dataloader, lr_scheduler\n",
    ")\n",
    "\n",
    "# COCO images\n",
    "cycle, optimizer, train_coco_dl, val_coco_dl, lr_scheduler = accelerator.prepare(\n",
    "    cycle, optimizer, train_coco_dl, val_coco_dl, lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "mse = nn.MSELoss()\n",
    "def loss_fnxn(clip_target=None, clip_pred=None, brain_target=None, brain_pred=None, alpha=1, loss_type=\"clip\"):\n",
    "    if loss_type==\"clip\":\n",
    "        loss = mse(clip_target, clip_pred)\n",
    "    elif loss_type==\"brain\":\n",
    "        loss = mse(brain_target, brain_pred)\n",
    "    elif loss_type==\"both\":\n",
    "        brain_loss = mse(brain_target, brain_pred)\n",
    "        clip_loss = mse(clip_target, clip_pred)\n",
    "        loss = clip_loss+alpha*brain_loss\n",
    "    else:\n",
    "        raise Exception(\"invalid loss type\")\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing starting with step 0 / 3470\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714c8ff53a20414d94ceab3bb4ed82be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training coco:   0%|          | 0/3471 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db9f9aa79bb4647a5e075e8065a72f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training algonauts:   0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving checkpoint\n",
      "saving /fsx/proj-medarc/fmri/dweisberg/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "losses, val_losses, lrs = [], [], []\n",
    "best_val_loss = 1e9\n",
    "\n",
    "# Optionally resume from checkpoint #\n",
    "if resume_from_ckpt:\n",
    "    print(\"\\n---resuming from last.pth ckpt---\\n\")\n",
    "    checkpoint = torch.load(outdir+'/last.pth')\n",
    "    step = checkpoint['step']\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "    cycle.load_state_dict(checkpoint['model_state_dict'])\n",
    "    losses = checkpoint['train_losses']\n",
    "    val_losses = checkpoint['val_losses']\n",
    "    \n",
    "print(f\"{model_name} starting with step {step} / {total_steps}\")\n",
    "\n",
    "progress_bar = enumerate(tqdm(train_coco_dl, desc='training coco', leave=False))\n",
    "\n",
    "# TODO: fast forward for resuming checkpoint. Is there a better way of doing this?\n",
    "if step!=0:\n",
    "    print(\"Fast forwarding...\")\n",
    "    i=0\n",
    "    while i<step-1:\n",
    "        i,_ = next(progress_bar)\n",
    "    print(\"Finished forwarding!\")\n",
    "\n",
    "# hyperparameters\n",
    "cocoRate = 1 # int number of COCO batches to algonauts batches\n",
    "alpha = 1 # coefficient of loss on brain activity in total loss\n",
    "\n",
    "alg_batches = itertools.cycle(enumerate(tqdm(train_alg_dl, desc='training algonauts', leave=False)))\n",
    "\n",
    "# training loop\n",
    "cycle.train()\n",
    "for step, coco_image in progress_bar:\n",
    "    if step%cocoRate==0:\n",
    "        alg_batch = next(alg_batches, None)\n",
    "        img_batches = [coco_image, alg_batch]\n",
    "    else:\n",
    "        img_batches = [coco_image]\n",
    "\n",
    "\n",
    "    for j, data in enumerate(img_batches):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    #         repeat_index = train_i % 3\n",
    "        if j!=0:\n",
    "            alg_index, (image, lh_vert, rh_vert) = data\n",
    "        else:\n",
    "            image = data\n",
    "\n",
    "        image = image.float()\n",
    "        clip_target = clip_extractor.embed_image(image).float()\n",
    "\n",
    "        # determines what kind of loss \n",
    "        if j!=0:\n",
    "            brain_target = torch.cat((lh_vert, rh_vert), 1)\n",
    "            brain_pred, clip_pred = cycle(clip_target, paired=True) \n",
    "            loss = loss_fnxn(clip_target=clip_target,clip_pred=clip_pred,\n",
    "                        brain_target=brain_target, brain_pred=brain_pred,\n",
    "                        alpha=alpha, loss_type=\"both\")\n",
    "        else:\n",
    "            clip_pred = cycle(clip_target) \n",
    "            loss = loss_fnxn(clip_target=clip_target, clip_pred=clip_pred, loss_type=\"clip\")\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        lrs.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "     # Save model checkpoint every `ckpt_interval`` steps or on the last step\n",
    "    if (ckpt_interval is not None and (step + 1) % ckpt_interval == 0) or step == num_steps - 1:\n",
    "        print(\"saving checkpoint\")\n",
    "        cycle.eval()\n",
    "        save_ckpt(f'last')\n",
    "        cycle.train()\n",
    "        \n",
    "    if (not save_at_end and not no_ckpt_saving) or (save_at_end and step == num_steps - 1):\n",
    "        # save best model\n",
    "        val_loss = np.mean(val_losses[-(val_i+1):])\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_ckpt('best')\n",
    "        else:\n",
    "            print(f'not best - val_loss: {val_loss:.3f}, best_val_loss: {best_val_loss:.3f}')\n",
    "    \n",
    "    # do validation set\n",
    "    if step % val_interval==0:\n",
    "        cycle.eval()\n",
    "        if local_rank==0: # i think its possible to remove this if statement though with some revisions\n",
    "            print(\"validating\")\n",
    "            for val_i, (image, lh_vert, rh_vert) in enumerate(tqdm(val_alg_dl, desc='validation', leave=False)): \n",
    "                with torch.no_grad():\n",
    "                    # repeat_index = val_i % 3\n",
    "\n",
    "                    image = image.float()\n",
    "\n",
    "                    clip_target = clip_extractor.embed_image(image).float()\n",
    "                    brain_target = torch.cat((lh_vert, rh_vert), 1)\n",
    "                    brain_pred, clip_pred = cycle(clip_target, paired=True) \n",
    "                    val_loss =  loss_fnxn(clip_target=clip_target,clip_pred=clip_pred,\n",
    "                                     brain_target=brain_target, brain_pred=brain_pred,\n",
    "                                     alpha=alpha, loss_type=\"both\")\n",
    "                    utils.check_loss(val_loss)\n",
    "                    val_losses.append(val_loss.item())\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(losses)\n",
    "        plt.title('Total Training loss')\n",
    "        plt.xlabel('steps')\n",
    "        plt.ylabel('Total Loss')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(val_losses)\n",
    "        plt.title('Total Validation Loss on Algonauts data')\n",
    "        plt.xlabel('steps')\n",
    "        plt.ylabel('Total Loss')\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        logs = {\"train/loss\": np.mean(losses[-(step+1):]),\n",
    "                \"val/loss\": np.mean(val_losses[-(step+1):]),\n",
    "                \"train/lr\": lrs[-1],\n",
    "                \"train/num_steps\": len(losses),\n",
    "                \"val/num_steps\": len(val_losses)}\n",
    "\n",
    "#         progress_bar.set_postfix(**logs)\n",
    "        cycle.train()\n",
    "\n",
    "    if distributed:\n",
    "        dist.barrier()\n",
    "\n",
    "print(\"\\n===Finished!===\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(losses))\n",
    "print(len(val_losses))\n",
    "plt.plot(losses)\n",
    "plt.title(str(cocoRate)+\" COCO batches(s) for every 1 algonauts batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses)\n",
    "plt.title('Total Training loss')\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('Total Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_losses)\n",
    "plt.title('Total Validation Loss on Algonauts data')\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('Total Loss')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
