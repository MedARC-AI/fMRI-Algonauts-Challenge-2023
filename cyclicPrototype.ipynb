{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "# get custom models and functions\n",
    "import sys\n",
    "sys.path.append('../fMRI-reconstruction-NSD/src')\n",
    "from models import Clipper, BrainNetwork\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from accelerate import Accelerator\n",
    "import argparse\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "distributed = False num_devices = 1 local rank = 0 world size = 1\n"
     ]
    }
   ],
   "source": [
    "# uses tf32 data type which is faster than standard float32\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# Multi-GPU config #\n",
    "accelerator = Accelerator()\n",
    "print = accelerator.print # only print if local_rank=0\n",
    "\n",
    "device = accelerator.device\n",
    "print(\"device:\",device)\n",
    "\n",
    "num_devices = torch.cuda.device_count()\n",
    "if num_devices==0: num_devices = 1\n",
    "num_workers = num_devices\n",
    "\n",
    "print(accelerator.state)\n",
    "local_rank = accelerator.state.local_process_index\n",
    "world_size = accelerator.state.num_processes\n",
    "if num_devices<=1 and world_size<=1:\n",
    "    distributed=False\n",
    "else:\n",
    "    distributed=True\n",
    "print(\"distributed =\",distributed,\"num_devices =\", num_devices, \"local rank =\", local_rank, \"world size =\", world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../algonauts_2023_challenge_data'\n",
    "parent_submission_dir = 'algonauts_2023_challenge_submission'\n",
    "\n",
    "subj = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--model_name=testing', '--clip_variant=ViT-L/14', '--batch_size=128', '--resume_from_ckpt']\n"
     ]
    }
   ],
   "source": [
    "# can specify jupyter_args here for argparser to use if running this code interactively\n",
    "if utils.is_interactive():\n",
    "    jupyter_args=[]\n",
    "    jupyter_args.append(\"--model_name=testing\")\n",
    "    jupyter_args.append(\"--clip_variant=ViT-L/14\")\n",
    "    jupyter_args.append(\"--batch_size=128\") # smaller to account for more loaded models.\n",
    "    jupyter_args.append(\"--resume_from_ckpt\")\n",
    "    print(jupyter_args)\n",
    "    \n",
    "    %load_ext autoreload\n",
    "    %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Model Training Configuration\")\n",
    "parser.add_argument(\n",
    "    \"--model_name\", type=str, default=\"testing\",\n",
    "    help=\"name of model, used for ckpt saving and wandb logging\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--batch_size\", type=int, default=300,\n",
    "    help=\"Our maximum for A100 was 300 for 1dim voxels and 128 for 3dim voxels\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--clip_variant\",type=str,default=\"ViT-L/14\",choices=[\"RN50\", \"ViT-L/14\", \"ViT-B/32\", \"ViT-H-14\", \"RN50x64\"],\n",
    "    help='clip / openclip variant',\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--outdir\",type=str,default=None,\n",
    "    help=\"output directory for logs and checkpoints\",\n",
    ")\n",
    "# doesn't work in python 3.8\n",
    "# parser.add_argument(\n",
    "#     \"--resume_from_ckpt\",action=argparse.BooleanOptionalAction,default=False,\n",
    "#     help=\"if not using wandb and want to resume from a ckpt\",\n",
    "# )\n",
    "parser.add_argument(\n",
    "    '--resume_from_ckpt',\n",
    "    action='store_true',\n",
    "    default=False,\n",
    "    help='if not using wandb and want to resume from a ckpt.',\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_epochs\",type=int,default=120,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--lr_scheduler\",type=str,default='cycle',choices=['cycle','fixed'],\n",
    ")\n",
    "# doesn't work in python 3.8\n",
    "# parser.add_argument(\n",
    "#     \"--ckpt_saving\",action=argparse.BooleanOptionalAction,default=True,\n",
    "# )\n",
    "parser.add_argument(\n",
    "    '--no_ckpt_saving',\n",
    "    action='store_false',\n",
    "    default=True,\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--ckpt_interval\",type=int,default=1,\n",
    "    help=\"save ckpt every x epochs\",\n",
    ")\n",
    "# parser.add_argument(\n",
    "#     \"--save_at_end\",action=argparse.BooleanOptionalAction,default=False,\n",
    "#     help=\"if False, will save best.ckpt whenever epoch shows best validation score\",\n",
    "# )\n",
    "parser.add_argument(\n",
    "    '--save_at_end',\n",
    "    action='store_true',\n",
    "    default=False,\n",
    "    help='if False, will save best.ckpt whenever epoch shows best validation score',\n",
    ")\n",
    "# parser.add_argument(\n",
    "#     \"--seed\",type=int,default=42,\n",
    "# )\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--max_lr\",type=float,default=3e-4,\n",
    ")\n",
    "\n",
    "if utils.is_interactive():\n",
    "    args = parser.parse_args(jupyter_args)\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "# create global variables without the args prefix\n",
    "for attribute_name in vars(args).keys():\n",
    "    globals()[attribute_name] = getattr(args, attribute_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if outdir is None:\n",
    "    outdir = os.path.abspath(f'train_logs/{model_name}')\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Models and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for dataloaders\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # convert the images to a PyTorch tensor\n",
    "])\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, imgs_paths, idxs, transform=None):\n",
    "        self.imgs_paths = np.array(imgs_paths)[idxs]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the image\n",
    "        img_path = self.imgs_paths[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        # Preprocess the image and send it to the chosen device ('cpu' or 'cuda')\n",
    "        if self.transform:\n",
    "            img = self.transform(img).to(device)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load COCO images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_dir = \"/scratch/gpfs/KNORMAN/COCO/unlabeled2017_all\"\n",
    "\n",
    "# Create list with all file names, sorted\n",
    "coco_list = os.listdir(coco_dir)\n",
    "coco_list.sort()\n",
    "\n",
    "rand_seed = 5 \n",
    "np.random.seed(rand_seed)\n",
    "\n",
    "# Calculate how many COCO images correspond to 90% for training\n",
    "num_train_coco = int(np.round(len(train_img_list) / 100 * 90))\n",
    "# Shuffle all training stimulus images\n",
    "idxs_coco = np.arange(len(coco_list))\n",
    "# np.random.shuffle(idxs)\n",
    "# Assign 90% of the shuffled images to the training partition,\n",
    "# and 10% to the test partition\n",
    "idxs_train_coco, idxs_val_coco = idxs[:num_train], idxs[num_train:]\n",
    "\n",
    "print('Training COCO images: ' + format(len(idxs_train)))\n",
    "print('\\nValidation COCO images: ' + format(len(idxs_val)))\n",
    "\n",
    "# Get the paths of all image files\n",
    "coco_paths = sorted(list(Path(coco_dir).iterdir()))\n",
    "# The DataLoaders contain the ImageDataset class\n",
    "train_coco_dl = DataLoader(\n",
    "    ImageDataset(coco_paths, idxs_train_coco, transform), \n",
    "    batch_size=batch_size, \n",
    ")\n",
    "val_coco_dl = DataLoader(\n",
    "    ImageDataset(coco_paths, idxs_val_coco, transform), \n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Algonauts Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 9841\n",
      "Test images: 159\n",
      "Training stimulus images: 8857\n",
      "\n",
      "Validation stimulus images: 984\n",
      "\n",
      "Test stimulus images: 159\n"
     ]
    }
   ],
   "source": [
    "class argObj:\n",
    "  def __init__(self, data_dir, parent_submission_dir, subj):\n",
    "    \n",
    "    self.subj = format(subj, '02')\n",
    "    self.data_dir = os.path.join(data_dir, 'subj'+self.subj)\n",
    "    self.parent_submission_dir = parent_submission_dir\n",
    "    self.subject_submission_dir = os.path.join(self.parent_submission_dir,\n",
    "        'subj'+self.subj)\n",
    "\n",
    "    # Create the submission directory if not existing\n",
    "    if not os.path.isdir(self.subject_submission_dir):\n",
    "        os.makedirs(self.subject_submission_dir)\n",
    "\n",
    "args = argObj(data_dir, parent_submission_dir, subj)\n",
    "\n",
    "train_img_dir  = os.path.join(args.data_dir, 'training_split', 'training_images')\n",
    "test_img_dir  = os.path.join(args.data_dir, 'test_split', 'test_images')\n",
    "\n",
    "# Create lists will all training and test image file names, sorted\n",
    "train_img_list = os.listdir(train_img_dir)\n",
    "train_img_list.sort()\n",
    "test_img_list = os.listdir(test_img_dir)\n",
    "test_img_list.sort()\n",
    "print('Training images: ' + str(len(train_img_list)))\n",
    "print('Test images: ' + str(len(test_img_list)))\n",
    "\n",
    "# Calculate how many stimulus images correspond to 90% of the training data\n",
    "num_train = int(np.round(len(train_img_list) / 100 * 90))\n",
    "# Shuffle all training stimulus images\n",
    "idxs = np.arange(len(train_img_list))\n",
    "# np.random.shuffle(idxs)\n",
    "# Assign 90% of the shuffled stimulus images to the training partition,\n",
    "# and 10% to the test partition\n",
    "idxs_train, idxs_val = idxs[:num_train], idxs[num_train:]\n",
    "# No need to shuffle or split the test stimulus images\n",
    "idxs_test = np.arange(len(test_img_list))\n",
    "\n",
    "print('Training stimulus images: ' + format(len(idxs_train)))\n",
    "print('\\nValidation stimulus images: ' + format(len(idxs_val)))\n",
    "print('\\nTest stimulus images: ' + format(len(idxs_test)))\n",
    "\n",
    "# Get the paths of all image files\n",
    "train_imgs_paths = sorted(list(Path(train_img_dir).iterdir()))\n",
    "test_imgs_paths = sorted(list(Path(test_img_dir).iterdir()))\n",
    "\n",
    "# The DataLoaders contain the ImageDataset class\n",
    "train_imgs_dataloader = DataLoader(\n",
    "    ImageDataset(train_imgs_paths, idxs_train, transform), \n",
    "    batch_size=batch_size, \n",
    ")\n",
    "val_imgs_dataloader = DataLoader(\n",
    "    ImageDataset(train_imgs_paths, idxs_val, transform), \n",
    "    batch_size=batch_size\n",
    ")\n",
    "test_imgs_dataloader = DataLoader(\n",
    "    ImageDataset(test_imgs_paths, idxs_test, transform), \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# training_clip_dir = \"/scratch/gpfs/dw26/algonauts_2023_challenge_data/subj01/training_split/training_clip\"\n",
    "# validation_clip_dir = \"/scratch/gpfs/dw26/algonauts_2023_challenge_data/subj01/training_split/validation_clip\"\n",
    "# test_clip_dir = \"/scratch/gpfs/dw26/algonauts_2023_challenge_data/subj01/test_split/test_clip\"\n",
    "\n",
    "# if not os.path.isdir(training_clip_dir):\n",
    "#     os.makedirs(training_clip_dir)\n",
    "# if not os.path.isdir(validation_clip_dir):\n",
    "#     os.makedirs(validation_clip_dir)\n",
    "# if not os.path.isdir(test_clip_dir):\n",
    "#     os.makedirs(test_clip_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT-L/14 cuda\n"
     ]
    }
   ],
   "source": [
    "# get clipper\n",
    "clip_extractor = Clipper(\"ViT-L/14\", device=torch.device(device)) # run in terminal to download\n",
    "\n",
    "# def img2clipfile(img_paths, dataloader, idxs, clip_dir):\n",
    "#     running_count=0\n",
    "#     for img_batch in tqdm(dataloader):\n",
    "#         clip_batch = clip_extractor.embed_image(img_batch)\n",
    "#         for clip in clip_batch:\n",
    "#             clip = clip.cpu().numpy()\n",
    "#             img_path = img_paths[idxs[running_count]]\n",
    "#             clip_file_name = str(img_path)[-24:-3]+\"npy\"\n",
    "#             np.save(os.path.join(training_clip_dir, clip_file_name), clip)\n",
    "#             running_count+=1\n",
    "        \n",
    "        \n",
    "# img2clipfile(train_imgs_paths, train_imgs_dataloader, idxs_train, training_clip_dir)\n",
    "# img2clipfile(train_imgs_paths, val_imgs_dataloader, idxs_val, validation_clip_dir)\n",
    "# img2clipfile(test_imgs_paths, test_imgs_dataloader, idxs_test, test_clip_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Clip2Vert and Vert2CLip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclePrototype(nn.Module):\n",
    "    def __init__(self, brain_dim, clip_dim):\n",
    "        super().__init__()\n",
    "        self.brain_dim = dict(out_dim=brain_dim, in_dim=clip_dim)\n",
    "        self.clip_dim = dict(out_dim=clip_dim, in_dim=brain_dim)\n",
    "        self.clip2vert = BrainNetwork(**self.brain_dim)\n",
    "        self.vert2clip = BrainNetwork(**self.clip_dim)\n",
    "    def forward(self, x):\n",
    "        x = self.clip2vert(x)\n",
    "        x = self.vert2clip(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params of cycle:\n",
      "param counts:\n",
      "263,527,832 total\n",
      "263,527,832 trainable\n",
      "\n",
      "Done with model preparations!\n"
     ]
    }
   ],
   "source": [
    "brain_dim = 15000\n",
    "clip_dim = 768\n",
    "cycle_kwargs = dict(brain_dim=brain_dim, clip_dim=clip_dim)\n",
    "cycle = CyclePrototype(**cycle_kwargs)\n",
    "\n",
    "print(\"params of cycle:\")\n",
    "if local_rank==0:\n",
    "    utils.count_params(cycle)\n",
    "    \n",
    "no_decay = ['bias']\n",
    "opt_grouped_parameters = [\n",
    "    {'params': [p for n, p in cycle.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 1e-2},\n",
    "    {'params': [p for n, p in cycle.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = torch.optim.AdamW(opt_grouped_parameters, lr=3e-4) # lr doesnt get used if lr_scheduler='cycle'\n",
    "\n",
    "if lr_scheduler == 'fixed':\n",
    "    lr_scheduler = None\n",
    "elif lr_scheduler == 'cycle':\n",
    "    global_batch_size = batch_size * num_devices\n",
    "    total_steps=num_epochs*(num_train//global_batch_size)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, \n",
    "        max_lr=max_lr,\n",
    "        total_steps=total_steps,\n",
    "        final_div_factor=1000,\n",
    "        last_epoch=-1, pct_start=2/num_epochs\n",
    "    )\n",
    "    \n",
    "def save_ckpt(tag):\n",
    "    ckpt_path = outdir+f'/{tag}.pth'\n",
    "    print(f'saving {ckpt_path}',flush=True)\n",
    "    state_dict = cycle.state_dict()\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': cycle.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'lr_scheduler': lr_scheduler.state_dict(),\n",
    "        'train_losses': losses,\n",
    "        'val_losses': val_losses,\n",
    "        'lrs': lrs,\n",
    "        }, ckpt_path)\n",
    "        \n",
    "print(\"\\nDone with model preparations!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'params': [Parameter containing:\n",
      "tensor([[ 0.0157,  0.0290,  0.0345,  ..., -0.0302, -0.0249, -0.0170],\n",
      "        [-0.0360,  0.0353, -0.0132,  ...,  0.0074, -0.0157, -0.0075],\n",
      "        [-0.0162,  0.0136, -0.0133,  ..., -0.0075,  0.0357, -0.0229],\n",
      "        ...,\n",
      "        [ 0.0284,  0.0025, -0.0121,  ..., -0.0114, -0.0156,  0.0032],\n",
      "        [-0.0089,  0.0354, -0.0077,  ..., -0.0018,  0.0014,  0.0167],\n",
      "        [ 0.0239,  0.0112, -0.0146,  ...,  0.0199, -0.0224, -0.0297]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0139, -0.0140, -0.0071,  ...,  0.0125,  0.0153, -0.0086],\n",
      "        [-0.0154,  0.0111, -0.0065,  ..., -0.0080,  0.0022, -0.0065],\n",
      "        [-0.0154,  0.0093,  0.0042,  ..., -0.0051, -0.0088,  0.0013],\n",
      "        ...,\n",
      "        [-0.0080, -0.0109,  0.0022,  ..., -0.0044,  0.0114,  0.0146],\n",
      "        [ 0.0028, -0.0118, -0.0131,  ...,  0.0135, -0.0017, -0.0079],\n",
      "        [-0.0144, -0.0146, -0.0108,  ..., -0.0094,  0.0119,  0.0010]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0021,  0.0024,  0.0155,  ...,  0.0023, -0.0119, -0.0017],\n",
      "        [ 0.0150, -0.0078,  0.0090,  ...,  0.0010, -0.0101, -0.0072],\n",
      "        [-0.0110,  0.0037, -0.0049,  ...,  0.0017,  0.0124, -0.0154],\n",
      "        ...,\n",
      "        [ 0.0109,  0.0126, -0.0074,  ...,  0.0070,  0.0085, -0.0072],\n",
      "        [ 0.0088, -0.0136, -0.0078,  ...,  0.0072, -0.0040,  0.0037],\n",
      "        [ 0.0109, -0.0092, -0.0088,  ...,  0.0126, -0.0015,  0.0054]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0152, -0.0037, -0.0110,  ..., -0.0074,  0.0112, -0.0052],\n",
      "        [-0.0155,  0.0023,  0.0045,  ...,  0.0053, -0.0116, -0.0132],\n",
      "        [-0.0148,  0.0054, -0.0042,  ...,  0.0106, -0.0099, -0.0051],\n",
      "        ...,\n",
      "        [ 0.0067,  0.0146, -0.0059,  ..., -0.0048, -0.0085, -0.0066],\n",
      "        [-0.0042, -0.0097, -0.0104,  ..., -0.0139, -0.0142,  0.0016],\n",
      "        [-0.0052, -0.0076, -0.0085,  ..., -0.0095, -0.0036,  0.0084]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0147, -0.0035, -0.0024,  ..., -0.0127,  0.0143, -0.0114],\n",
      "        [ 0.0127,  0.0080, -0.0090,  ..., -0.0032, -0.0089,  0.0137],\n",
      "        [-0.0021,  0.0116, -0.0109,  ...,  0.0111, -0.0051,  0.0108],\n",
      "        ...,\n",
      "        [ 0.0152,  0.0135,  0.0052,  ...,  0.0102,  0.0033, -0.0053],\n",
      "        [ 0.0090,  0.0021, -0.0036,  ..., -0.0156,  0.0121, -0.0023],\n",
      "        [-0.0100, -0.0140,  0.0011,  ...,  0.0065,  0.0057,  0.0011]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0074,  0.0152, -0.0074,  ..., -0.0137, -0.0096, -0.0028],\n",
      "        [ 0.0060, -0.0094,  0.0061,  ..., -0.0016,  0.0117,  0.0125],\n",
      "        [-0.0146,  0.0152,  0.0016,  ..., -0.0071, -0.0113,  0.0056],\n",
      "        ...,\n",
      "        [ 0.0100, -0.0119, -0.0035,  ...,  0.0097,  0.0041, -0.0092],\n",
      "        [-0.0015,  0.0025,  0.0151,  ..., -0.0113,  0.0140, -0.0039],\n",
      "        [ 0.0007, -0.0062,  0.0127,  ..., -0.0111, -0.0085, -0.0136]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0041, -0.0007,  0.0010,  ..., -0.0063, -0.0052, -0.0015],\n",
      "        [-0.0067,  0.0023, -0.0004,  ...,  0.0052,  0.0038, -0.0049],\n",
      "        [ 0.0023,  0.0005,  0.0032,  ...,  0.0063,  0.0053,  0.0047],\n",
      "        ...,\n",
      "        [ 0.0025,  0.0025,  0.0006,  ..., -0.0016, -0.0016, -0.0078],\n",
      "        [-0.0065, -0.0006,  0.0064,  ...,  0.0045, -0.0026, -0.0075],\n",
      "        [-0.0080, -0.0048,  0.0032,  ..., -0.0047, -0.0023,  0.0053]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0057, -0.0062, -0.0124,  ..., -0.0040, -0.0047,  0.0140],\n",
      "        [ 0.0075,  0.0115, -0.0005,  ..., -0.0144, -0.0040,  0.0122],\n",
      "        [ 0.0074, -0.0155,  0.0104,  ..., -0.0013,  0.0118,  0.0109],\n",
      "        ...,\n",
      "        [ 0.0045,  0.0125, -0.0123,  ...,  0.0009,  0.0007,  0.0100],\n",
      "        [ 0.0139,  0.0009,  0.0023,  ...,  0.0134, -0.0081,  0.0089],\n",
      "        [-0.0129,  0.0094,  0.0127,  ..., -0.0048,  0.0125, -0.0153]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([[-2.7339e-03, -6.9698e-03,  9.9562e-03,  ..., -1.4507e-03,\n",
      "          4.0755e-05, -1.5778e-03],\n",
      "        [ 6.0713e-03, -1.0178e-02, -1.4174e-02,  ...,  5.6073e-03,\n",
      "         -4.3433e-03, -4.8880e-03],\n",
      "        [-1.1275e-02, -1.0317e-02,  4.6298e-04,  ..., -7.0423e-03,\n",
      "         -3.9923e-03,  1.0325e-02],\n",
      "        ...,\n",
      "        [ 1.1746e-02,  9.1157e-03, -3.8644e-03,  ...,  5.8364e-04,\n",
      "          9.6521e-03, -2.0555e-03],\n",
      "        [ 7.2512e-03,  1.1742e-02, -7.1284e-03,  ..., -5.5183e-03,\n",
      "          3.4208e-03, -1.4566e-02],\n",
      "        [-5.7191e-03,  3.9593e-03,  1.2350e-02,  ...,  1.3319e-02,\n",
      "         -1.0262e-02,  9.6498e-03]], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0108,  0.0142,  0.0136,  ..., -0.0016,  0.0118,  0.0073],\n",
      "        [-0.0119, -0.0135,  0.0054,  ...,  0.0014, -0.0041,  0.0060],\n",
      "        [-0.0108,  0.0067, -0.0085,  ...,  0.0123,  0.0071, -0.0115],\n",
      "        ...,\n",
      "        [-0.0035,  0.0085,  0.0012,  ...,  0.0036,  0.0001, -0.0040],\n",
      "        [ 0.0065, -0.0119,  0.0018,  ..., -0.0105, -0.0082,  0.0004],\n",
      "        [-0.0032,  0.0102,  0.0047,  ..., -0.0149, -0.0009, -0.0149]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0022,  0.0005,  0.0120,  ...,  0.0131,  0.0062, -0.0068],\n",
      "        [ 0.0006, -0.0123, -0.0106,  ...,  0.0140,  0.0053,  0.0009],\n",
      "        [-0.0076, -0.0043,  0.0141,  ...,  0.0041,  0.0136, -0.0023],\n",
      "        ...,\n",
      "        [-0.0076, -0.0015, -0.0091,  ...,  0.0121,  0.0050,  0.0042],\n",
      "        [-0.0136, -0.0131, -0.0147,  ..., -0.0142, -0.0112,  0.0088],\n",
      "        [ 0.0090,  0.0151, -0.0144,  ...,  0.0043,  0.0040,  0.0044]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0029, -0.0006,  0.0103,  ..., -0.0142,  0.0083,  0.0109],\n",
      "        [-0.0115, -0.0068,  0.0118,  ..., -0.0109, -0.0155, -0.0122],\n",
      "        [ 0.0143, -0.0015, -0.0100,  ..., -0.0073, -0.0028,  0.0029],\n",
      "        ...,\n",
      "        [ 0.0012, -0.0078, -0.0115,  ...,  0.0041, -0.0051, -0.0056],\n",
      "        [ 0.0047,  0.0006, -0.0122,  ..., -0.0099,  0.0019,  0.0075],\n",
      "        [-0.0007,  0.0109, -0.0156,  ...,  0.0071, -0.0061,  0.0073]],\n",
      "       requires_grad=True)], 'weight_decay': 0.01, 'lr': 1.200000000000002e-05, 'betas': (0.95, 0.999), 'eps': 1e-08, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'initial_lr': 1.1999999999999999e-05, 'max_lr': 0.0003, 'min_lr': 1.1999999999999998e-08, 'max_momentum': 0.95, 'base_momentum': 0.85}\n"
     ]
    }
   ],
   "source": [
    "print(opt_grouped_parameters[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Huggingface Accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algonauts images\n",
    "# cycle, optimizer, train_imgs_dataloader, val_imgs_dataloader, test_imgs_dataloader, lr_scheduler = accelerator.prepare(\n",
    "#     cycle, optimizer, train_imgs_dataloader, val_imgs_dataloader, test_imgs_dataloader, lr_scheduler\n",
    "# )\n",
    "\n",
    "# COCO images\n",
    "cycle, optimizer, train_imgs_dataloader, val_imgs_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    cycle, optimizer, train_coco_dl, val_coco_dl, lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---resuming from last.pth ckpt---\n",
      "\n",
      "testing starting with epoch 99 / 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██████████████████████████████████████████████████▉                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | 1/21 [01:27<29:05, 87.27s/it, train/loss=0.0344, train/lr=1.26e-5, train/num_steps=7210, val/loss=0.0302, val/num_steps=824]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | 2/21 [02:48<26:35, 83.95s/it, train/loss=0.0343, train/lr=1.1e-5, train/num_steps=7280, val/loss=0.0302, val/num_steps=832]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 3/21 [04:10<24:53, 82.97s/it, train/loss=0.034, train/lr=9.57e-6, train/num_steps=7350, val/loss=0.0301, val/num_steps=840]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | 4/21 [05:32<23:19, 82.31s/it, train/loss=0.0339, train/lr=8.19e-6, train/num_steps=7420, val/loss=0.0301, val/num_steps=848]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | 5/21 [06:56<22:06, 82.94s/it, train/loss=0.0337, train/lr=6.93e-6, train/num_steps=7490, val/loss=0.03, val/num_steps=856]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | 6/21 [08:19<20:47, 83.19s/it, train/loss=0.0336, train/lr=5.76e-6, train/num_steps=7560, val/loss=0.03, val/num_steps=864]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | 7/21 [09:41<19:17, 82.69s/it, train/loss=0.0334, train/lr=4.7e-6, train/num_steps=7630, val/loss=0.0301, val/num_steps=872]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 8/21 [11:02<17:49, 82.30s/it, train/loss=0.0333, train/lr=3.75e-6, train/num_steps=7700, val/loss=0.0299, val/num_steps=880]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | 9/21 [12:25<16:29, 82.49s/it, train/loss=0.0333, train/lr=2.91e-6, train/num_steps=7770, val/loss=0.0299, val/num_steps=888]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | 10/21 [13:50<15:16, 83.33s/it, train/loss=0.0332, train/lr=2.17e-6, train/num_steps=7840, val/loss=0.0299, val/num_steps=896]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | 11/21 [15:18<14:05, 84.58s/it, train/loss=0.0331, train/lr=1.54e-6, train/num_steps=7910, val/loss=0.0299, val/num_steps=904]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | 12/21 [16:45<12:48, 85.38s/it, train/loss=0.0331, train/lr=1.02e-6, train/num_steps=7980, val/loss=0.0298, val/num_steps=912]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                                                                                                                                                                                                                                                                                                       | 13/21 [18:12<11:26, 85.85s/it, train/loss=0.033, train/lr=6.02e-7, train/num_steps=8050, val/loss=0.0298, val/num_steps=920]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                                                                                                                                                                                                    | 14/21 [19:38<10:00, 85.74s/it, train/loss=0.033, train/lr=2.98e-7, train/num_steps=8120, val/loss=0.0298, val/num_steps=928]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                                                                                                                                                 | 15/21 [20:59<08:26, 84.42s/it, train/loss=0.033, train/lr=1.02e-7, train/num_steps=8190, val/loss=0.0298, val/num_steps=936]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                                                                                                                              | 16/21 [22:20<06:57, 83.44s/it, train/loss=0.033, train/lr=1.65e-8, train/num_steps=8260, val/loss=0.0298, val/num_steps=944]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                                                                           | 17/21 [23:43<05:33, 83.33s/it, train/loss=0.033, train/lr=1.2e-8, train/num_steps=8330, val/loss=0.0298, val/num_steps=952]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                        | 18/21 [25:04<04:07, 82.64s/it, train/loss=0.033, train/lr=1.2e-8, train/num_steps=8400, val/loss=0.0298, val/num_steps=960]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                      | 19/21 [26:25<02:44, 82.22s/it, train/loss=0.033, train/lr=1.2e-8, train/num_steps=8470, val/loss=0.0298, val/num_steps=968]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                   | 20/21 [27:47<01:21, 81.93s/it, train/loss=0.033, train/lr=1.2e-8, train/num_steps=8540, val/loss=0.0298, val/num_steps=976]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /scratch/gpfs/dw26/fMRI-Algonauts-Challenge-2023/train_logs/testing/last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [29:09<00:00, 83.30s/it, train/loss=0.033, train/lr=1.2e-8, train/num_steps=8610, val/loss=0.0298, val/num_steps=984]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Finished!===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "losses, val_losses, lrs = [], [], []\n",
    "best_val_loss = 1e9\n",
    "\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "# Optionally resume from checkpoint #\n",
    "if resume_from_ckpt:\n",
    "    print(\"\\n---resuming from last.pth ckpt---\\n\")\n",
    "    checkpoint = torch.load(outdir+'/last.pth')\n",
    "    epoch = checkpoint['epoch']\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "    cycle.load_state_dict(checkpoint['model_state_dict'])\n",
    "    losses = checkpoint['train_losses']\n",
    "    val_losses = checkpoint['val_losses']\n",
    "    \n",
    "print(f\"{model_name} starting with epoch {epoch} / {num_epochs}\")\n",
    "progress_bar = tqdm(range(epoch,num_epochs), ncols=1200, disable=(local_rank!=0))\n",
    "for epoch in progress_bar:\n",
    "    cycle.train()\n",
    "\n",
    "    for train_i, image in enumerate(train_imgs_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "#         repeat_index = train_i % 3\n",
    "\n",
    "        image = image.float()\n",
    "        clip_target = clip_extractor.embed_image(image).float()\n",
    "        clip_cycle = cycle(clip_target) \n",
    "\n",
    "        loss = mse(clip_target, clip_cycle)\n",
    "        losses.append(loss.item())\n",
    "        lrs.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "    cycle.eval()\n",
    "    if local_rank==0: # i think its possible to remove this if statement though with some revisions\n",
    "        for val_i, image in enumerate(val_imgs_dataloader): \n",
    "            with torch.no_grad():\n",
    "                # repeat_index = val_i % 3\n",
    "\n",
    "                image = image.float()\n",
    "\n",
    "                clip_target = clip_extractor.embed_image(image).float()\n",
    "                clip_cycle = cycle(clip_target) \n",
    "                val_loss =  mse(clip_target, clip_cycle)\n",
    "                utils.check_loss(val_loss)\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "        if (not save_at_end and not no_ckpt_saving) or (save_at_end and epoch == num_epochs - 1):\n",
    "            # save best model\n",
    "            val_loss = np.mean(val_losses[-(val_i+1):])\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                save_ckpt('best')\n",
    "            else:\n",
    "                print(f'not best - val_loss: {val_loss:.3f}, best_val_loss: {best_val_loss:.3f}')\n",
    "        \n",
    "        # Save model checkpoint every `ckpt_interval`` epochs or on the last epoch\n",
    "        if (ckpt_interval is not None and (epoch + 1) % ckpt_interval == 0) or epoch == num_epochs - 1:\n",
    "            save_ckpt(f'last')\n",
    "\n",
    "        logs = {\"train/loss\": np.mean(losses[-(train_i+1):]),\n",
    "                \"val/loss\": np.mean(val_losses[-(val_i+1):]),\n",
    "                \"train/lr\": lrs[-1],\n",
    "                \"train/num_steps\": len(losses),\n",
    "                \"val/num_steps\": len(val_losses)}\n",
    "        \n",
    "        progress_bar.set_postfix(**logs)\n",
    "            \n",
    "    if distributed:\n",
    "        dist.barrier()\n",
    "\n",
    "print(\"\\n===Finished!===\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8610\n",
      "984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x147ff3489ee0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(losses))\n",
    "print(len(val_losses))\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14801e79f310>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Get fMRI data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fmri_dir = os.path.join(args.data_dir, 'training_split', 'training_fmri')\n",
    "# lh_fmri = np.load(os.path.join(fmri_dir, 'lh_training_fmri.npy'))\n",
    "# rh_fmri = np.load(os.path.join(fmri_dir, 'rh_training_fmri.npy'))\n",
    "\n",
    "# print('LH training fMRI data shape:')\n",
    "# print(lh_fmri.shape)\n",
    "# print('(Training stimulus images × LH vertices)')\n",
    "\n",
    "# print('\\nRH training fMRI data shape:')\n",
    "# print(rh_fmri.shape)\n",
    "# print('(Training stimulus images × RH vertices)')\n",
    "\n",
    "# lh_fmri_train = lh_fmri[idxs_train]\n",
    "# lh_fmri_val = lh_fmri[idxs_val]\n",
    "# rh_fmri_train = rh_fmri[idxs_train]\n",
    "# rh_fmri_val = rh_fmri[idxs_val]\n",
    "\n",
    "# del lh_fmri, rh_fmri\n",
    "\n",
    "# del lh_fmri_train, lh_fmri_val,rh_fmri_train,rh_fmri_val\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
